import os
import re
import json
import logging
import requests
import spacy
from fastapi.middleware.cors import CORSMiddleware
from fastapi import FastAPI, Request, Response
from pydantic import BaseModel
from dotenv import load_dotenv
<<<<<<< HEAD

from config import Settings
from api_clients import build_clients
from intents import IntentClassifier
from constants import SYSTEM_PROMPT

=======
from config import Settings
from api_clients import build_clients
from intents import IntentClassifier

# Î•Î¹ÏƒÎ¬Î³Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î½Î­ÎµÏ‚ ÏƒÏ…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚
from funny_responses import (
    funny_trip_response,
    trip_cost_response,
    funny_contact_response,
    funny_pharmacy_response,
    funny_hospital_response,
    funny_services_response,
    funny_patras_response,
    funny_default_response,
)

>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
# === Init Logger ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === Load NLP ===
<<<<<<< HEAD
# Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Ï†Î¿ÏÏ„ÏÏƒÎ¿Ï…Î¼Îµ Ï„Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿, Î±Î»Î»Î¹ÏÏ‚ Ï€ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î® ÏƒÏ„Î± Î±Î³Î³Î»Î¹ÎºÎ¬
=======
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
try:
    spacy.load("el_core_news_sm")
except Exception:
    spacy.load("en_core_web_sm")

# === Load ENV / Config ===
load_dotenv()
settings = Settings()

# === Init FastAPI & Settings ===
app = FastAPI()

# === Handle CORS ===
origins = ["*"] if settings.cors_origins == "*" else [o.strip() for o in settings.cors_origins.split(",")]
logger.info(f"CORS Origins Loaded: {origins}")

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=(origins != ["*"]),
    allow_methods=["*"],
    allow_headers=["*"],
)

# === Init Clients and Classifier ===
clients = build_clients(settings)
classifier = IntentClassifier(settings.intents_path)

# === Load local JSON knowledge at startup ===
@app.on_event("startup")
def load_local_knowledge():
    app.state.knowledge_base = {}
    data_folder = "data"
    if not os.path.exists(data_folder):
        logger.warning("âš  ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ 'data/' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.")
        return
    for filename in os.listdir(data_folder):
        if filename.endswith(".json"):
            key = filename.replace(".json", "")
            try:
                with open(os.path.join(data_folder, filename), "r", encoding="utf-8") as f:
                    app.state.knowledge_base[key] = json.load(f)
                    logger.info(f"âœ… Loaded: {filename}")
            except Exception as e:
                logger.error(f"âŒ Failed to load {filename}: {e}")

# === Models ===
class ChatRequest(BaseModel):
    message: str

# === Helper functions ===
def ask_llm_with_system_prompt(user_message: str, context_text: str) -> str:
    """
    ÎšÎ±Î»ÎµÎ¯ Ï„Î¿ OpenAI API Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î¿ SYSTEM_PROMPT ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î· Ï‡Î¹Î¿Ï…Î¼Î¿ÏÎ¹ÏƒÏ„Î¹ÎºÎ® Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·.
    """
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": f"{user_message}\n\nÎ Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Î²Î¿Î®Î¸ÎµÎ¹Î±:\n{context_text}",
        },
    ]
    payload = {
        "model": "gpt-3.5-turbo",
        "messages": messages,
        "temperature": 0.7,
        "presence_penalty": 0.6,
        "frequency_penalty": 0.2,
    }
    headers = {
        "Authorization": f"Bearer {settings.openai_api_key}",
        "Content-Type": "application/json",
    }
    try:
        resp = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=10,
        )
        resp.raise_for_status()
        return resp.json()["choices"][0]["message"]["content"]
    except Exception as e:
        logger.error(f"OpenAI call failed: {e}")
        return "âš  Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î± Î¼Îµ Ï„Î¿ LLM."

def simple_location_extractor(text: str):
    """
    Î•Î½Î¹ÏƒÏ‡Ï…Î¼Î­Î½Î¿ extraction Î³Î¹Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬!
    - Î ÏÏÏ„Î± Î²ÏÎ¯ÏƒÎºÎµÎ¹ full routes: "Î±Ï€Î¿ Î Î¬Ï„ÏÎ± Î¼Î­Ï‡ÏÎ¹ Î‘Î¸Î®Î½Î±"
    - ÎœÎµÏ„Î¬ Î²ÏÎ¯ÏƒÎºÎµÎ¹ Î±Ï€Î»Î¬ "ÏƒÏ„Î·Î½/ÏƒÏ„Î¿/Î³Î¹Î±/Ï€ÏÎ¿Ï‚ Î‘Î¸Î®Î½Î±"
    - Î‘Î½ Î²ÏÎµÎ¹ Î¼ÏŒÎ½Î¿ Î¼Î¹Î± Î»Î­Î¾Î· (Ï€.Ï‡. "Î‘Î¸Î®Î½Î±") Ï„Î· Î¸ÎµÏ‰ÏÎµÎ¯ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒ, Î¼Îµ default FROM = Î Î¬Ï„ÏÎ±
    """
<<<<<<< HEAD
    pattern = r"Î±Ï€Î¿\s+(?P<from>\w+).*?(?:Î¼ÎµÏ‡ÏÎ¹|Î¼Î­Ï‡ÏÎ¹|Ï€ÏÎ¿Ï‚|Î³Î¹Î±|ÎµÏ‰Ï‚)\s+(?P<to>\w+)"
=======
    # pattern Î¼Îµ Î¿Î½Î¿Î¼Î±ÏƒÏ„Î¹ÎºÎ¬ groups
    pattern = r"Î±Ï€Î¿\s+(?P<from>\w+).*?(?:Î¼ÎµÏ‡ÏÎ¹|Ï€ÏÎ¿Ï‚|Î³Î¹Î±|ÎµÏ‰Ï‚|Î¼Î­Ï‡ÏÎ¹)\s+(?P<to>\w+)"
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
    match = re.search(pattern, text.lower())
    if match:
        return {"FROM": match.group("from").capitalize(), "TO": match.group("to").capitalize()}
    loc_match = re.search(r"(?:ÏƒÏ„Î·Î½|ÏƒÏ„Î·|ÏƒÏ„Î¿|Î³Î¹Î±|Ï€ÏÎ¿Ï‚)\s+(?P<to>\w+)", text.lower())
    if loc_match:
        return {"FROM": "Î Î¬Ï„ÏÎ±", "TO": loc_match.group("to").capitalize()}
    single_word = text.strip().capitalize()
    if single_word and len(single_word) < 20 and all(c.isalpha() for c in single_word):
        return {"FROM": "Î Î¬Ï„ÏÎ±", "TO": single_word}
    return {}

# === ROUTES ===
@app.post("/chat")
async def chat_endpoint(request: Request):
    body = await request.json()
    user_message = body.get("message", "")
    result = classifier.detect(user_message)
    intent = result.get("intent")
    entities = result.get("entities", {})
    logger.info(f"[INTENT]: {intent}, [ENTITIES]: {entities}")
    kb = app.state.knowledge_base

    # Contact info
    if intent == "ContactInfoIntent":
        contact_base = kb.get("contact", {})
        info = contact_base.get("contact", {})
        if info:
<<<<<<< HEAD
            context = (
                f"{contact_base.get('organization', 'Taxi Express Î Î¬Ï„ÏÎ±Ï‚')}\n"
                f"Î¤Î·Î»Î­Ï†Ï‰Î½Î¿: {info.get('phone')}\n"
                f"Site: {info.get('website')}\n"
                f"Email: {info.get('email')}\n"
                f"Î”Î¹ÎµÏÎ¸Ï…Î½ÏƒÎ·: {info.get('address')}"
            )
        else:
            context = "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚ ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½."
        reply = ask_llm_with_system_prompt(user_message, context)
        return {"reply": reply}
=======
            # Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½, ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î± Ï€Î»Î®ÏÎ· ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±
            return {
                "reply": (
                    f"ğŸš– {contact_base.get('organization', 'Taxi Express Î Î¬Ï„ÏÎ±Ï‚')}\n"
                    f"ğŸ“ {info.get('phone')}\n"
                    f"ğŸŒ {info.get('website')}\n"
                    f"ğŸ“§ {info.get('email')}\n"
                    f"ğŸ“ {info.get('address')}"
                )
            }
        return {"reply": funny_contact_response()}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8

    # Î•ÎºÎ´ÏÎ¿Î¼Î­Ï‚/Ï…Ï€Î·ÏÎµÏƒÎ¯ÎµÏ‚
    if intent == "ServicesAndToursIntent":
        tours = kb.get("services_and_tours", {})
        if tours:
<<<<<<< HEAD
            text = tours.get("summary", "") + "\n"
            for val in tours.get("services", {}).values():
                text += f"{val}\n"
            for tour in tours.get("tours", []):
                text += (
                    f"{tour['title']} â€“ {tour['price']} â€“ {tour['duration']}\n"
                    f"Î ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹: {tour['includes']}\n"
                    f"Î”ÎµÎ½ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹: {tour['not_included']}\n"
                )
        else:
            text = "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± ÎµÎºÎ´ÏÎ¿Î¼Î­Ï‚."
        reply = ask_llm_with_system_prompt(user_message, text.strip())
        return {"reply": reply}
=======
            return {"reply": funny_services_response(
                tours.get("summary", ""),
                tours.get("services", {}),
                tours.get("tours", []),
            )}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8

    # Î Î±Ï„ÏÎ± LLM Answers (generic info)
    if intent == "PatrasLlmAnswersIntent":
        try:
            resp = clients["patras-llm-answers"].answer(user_message)
<<<<<<< HEAD
            # resp Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎ¯Î½Î±Î¹ dict Î® string
            if isinstance(resp, dict):
                base_answer = resp.get("answer") or resp.get("reply") or json.dumps(resp, ensure_ascii=False)
            else:
                base_answer = resp
            reply = ask_llm_with_system_prompt(user_message, base_answer)
            return {"reply": reply}
=======
            return {"reply": funny_patras_response(resp)}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
        except Exception as e:
            logger.error(f"Patras LLM Answers client error: {e}")
            return {"reply": "âŒ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½."}

<<<<<<< HEAD
    # Î•Ï†Î·Î¼ÎµÏÎµÏÎ¿Î½Ï„Î± Ï†Î±ÏÎ¼Î±ÎºÎµÎ¯Î±
    if intent == "OnDutyPharmacyIntent":
=======
    elif intent == "OnDutyPharmacyIntent":
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
        area = entities.get("AREA", "Î Î¬Ï„ÏÎ±")
        try:
            response = clients["pharmacy"].get_on_duty(area=area, method="get")
            pharmacies = response.get("pharmacies", [])
<<<<<<< HEAD
            if pharmacies:
                context = "\n".join([f"{p['name']} â€“ {p['address']} ({p['time_range']})" for p in pharmacies])
            else:
                context = f"Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎµÏ†Î·Î¼ÎµÏÎµÏÎ¿Î½Ï„Î± Ï†Î±ÏÎ¼Î±ÎºÎµÎ¯Î± ÏƒÏ„Î·Î½ Ï€ÎµÏÎ¹Î¿Ï‡Î® {area}."
            reply = ask_llm_with_system_prompt(user_message, context)
            return {"reply": reply}
=======
            return {"reply": funny_pharmacy_response(pharmacies)}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
        except Exception as e:
            logger.error(f"Pharmacy client error: {e}")
            return {"reply": "âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ Ï†Î±ÏÎ¼Î±ÎºÎµÎ¯Ï‰Î½."}

    # Î•Ï†Î·Î¼ÎµÏÎµÏÎ¿Î½Ï„Î± Î½Î¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¯Î±
    if intent == "HospitalIntent":
        try:
            resp = clients["hospital"].info()
<<<<<<< HEAD
            if isinstance(resp, str):
                context = resp
            else:
                # Î‘Î½Î±Î¼Î­Î½Î¿Ï…Î¼Îµ Î´Î¿Î¼Î® {"hospitals": [...], "on_call_message": "..."}
                hospitals = resp.get("hospitals", [])
                on_call_msg = resp.get("on_call_message", "")
                if hospitals:
                    context = "\n".join([f"{h['name']} â€“ {h['address']} ({h.get('phone','')})" for h in hospitals])
                    if on_call_msg:
                        context += f"\n{on_call_msg}"
                else:
                    context = "Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î½Î¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¯Ï‰Î½."
            reply = ask_llm_with_system_prompt(user_message, context)
            return {"reply": reply}
=======
            # Î±Î½ Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÎµÎ¯Î½Î±Î¹ string, Ï€ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ Î±Ï€Î»ÏÏ‚ Ï‡Î¹Î¿Ï…Î¼Î¿ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ ÎµÏ€Î¯Î»Î¿Î³Î¿
            if isinstance(resp, str):
                return {"reply": resp + "\nğŸ’‰ ÎœÎ·Î½ Î¾ÎµÏ‡Î½Î¬Ï‚ Î½Î± Ï†Î¿ÏÎ¬Ï‚ Î¶ÏÎ½Î· Î±ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚!"}
            # Î±Î½ ÎµÏ€Î¹ÏƒÏ„ÏÎ±Ï†ÎµÎ¯ Î´Î¿Î¼Î·Î¼Î­Î½Î¿ dict:
            hospitals = resp.get("hospitals", [])
            on_call_msg = resp.get("on_call_message", "")
            return {"reply": funny_hospital_response(hospitals, on_call_msg)}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
        except Exception as e:
            logger.error(f"Hospital client error: {e}")
            return {"reply": "âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ ÏƒÏÏƒÏ„Î·Î¼Î± Î½Î¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¯Ï‰Î½."}

    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎºÏŒÏƒÏ„Î¿Ï…Ï‚ Ï„Î±Î¾Î¹Î´Î¹Î¿Ï
    if intent == "TripCostIntent":
        origin = entities.get("FROM")
        destination = entities.get("TO")
        # ÎšÎ¬Î½Îµ Î­Î¾Ï„ÏÎ± extraction Î±Î½ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ TO
        if not destination:
            fallback = simple_location_extractor(user_message)
            origin = origin or fallback.get("FROM", "Î Î¬Ï„ÏÎ±")
            destination = fallback.get("TO")
        # Î‘Î½ Î´ÏŒÎ¸Î·ÎºÎµ Î¼ÏŒÎ½Î¿ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ (Î¼Î¯Î± Î»Î­Î¾Î·)
        if not destination and len(user_message.strip().split()) == 1 and user_message.strip().isalpha():
            origin = "Î Î¬Ï„ÏÎ±"
            destination = user_message.strip().capitalize()
        if destination:
            travel_kb = kb.get("travel_costs", {})
            cost_info = travel_kb.get(destination.lower())
            if cost_info:
<<<<<<< HEAD
                base_text = f"Î‘Ï€ÏŒÏƒÏ„Î±ÏƒÎ· {origin}â€“{destination}: ÎºÏŒÏƒÏ„Î¿Ï‚ {cost_info['cost']}â‚¬"
                reply = ask_llm_with_system_prompt(user_message, base_text)
                return {"reply": reply}
=======
                # Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ Ï‡Î¹Î¿Ï…Î¼Î¿ÏÎ¹ÏƒÏ„Î¹ÎºÏŒ trip_response
                return {"reply": funny_trip_response(origin, destination, cost_info['cost'])}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
            else:
                try:
                    # ÎºÎ±Ï„Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¹ ÏƒÏ„Î­Î»Î½Î¿Ï…Î¼Îµ ÏƒÏ„Î¿ timologio Î³Î¹Î± debugging
                    logger.debug(f"Timologio request: origin={origin}, destination={destination}")
                    result = clients["timologio"].calculate({"origin": origin, "destination": destination})
<<<<<<< HEAD
                    # Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Î²ÏÎ¿ÏÎ¼Îµ Ï„Î¹Î¼Î® ÏƒÏ„Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±
=======
                    # Î±Î½ Ï„Î¿ API Î¼Î±Ï‚ ÎµÏ€Î¹ÏƒÏ„ÏÎ­ÏˆÎµÎ¹ Ï„Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚, Ï„Î¿ Ï€ÎµÏÎ½Î¬Î¼Îµ ÏƒÏ„Î· Ï‡Î¹Î¿Ï…Î¼Î¿ÏÎ¹ÏƒÏ„Î¹ÎºÎ® Î±Ï€ÏŒÎºÏÎ¹ÏƒÎ·
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
                    price = None
                    for key in ("total_fare", "total_cost", "fare"):
                        if key in result:
                            price = result[key]
                            break
                    if price is not None:
<<<<<<< HEAD
                        context = f"ÎšÏŒÏƒÏ„Î¿Ï‚ {origin}â€“{destination}: {price}â‚¬"
                    else:
                        # Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¹Î¼Î®, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ ÏŒÎ»Î¿ Ï„Î¿ JSON
                        context = json.dumps(result, ensure_ascii=False)
                    reply = ask_llm_with_system_prompt(user_message, context)
                    return {"reply": reply}
=======
                        return {"reply": funny_trip_response(origin, destination, price)}
                    return {"reply": funny_patras_response(result)}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8
                except Exception as e:
                    logger.error(f"TripCost client error: {e}")
                    return {"reply": "âŒ Î£Ï†Î¬Î»Î¼Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Ï ÎºÏŒÏƒÏ„Î¿Ï…Ï‚."}
        # Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚
        return {"reply": ask_llm_with_system_prompt(user_message, "Î”ÎµÎ½ Î´ÏŒÎ¸Î·ÎºÎµ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚.")}

<<<<<<< HEAD
    # Î‘Î½ Î´ÎµÎ½ Î±Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÏ„Î·ÎºÎµ Ï€ÏÏŒÎ¸ÎµÏƒÎ· â€“ fallback
    unknown_reply = ask_llm_with_system_prompt(user_message, "Î”ÎµÎ½ Î±Î½Î±Î³Î½Ï‰ÏÎ¯Î¶Ï‰ Î±Ï…Ï„Î®Î½ Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·.")
    return {"reply": unknown_reply}
=======
    # Î‘Î½ Î´ÎµÎ½ Î±Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÏ„Î·ÎºÎµ ÎºÎ±Î¼Î¯Î± Ï€ÏÏŒÎ¸ÎµÏƒÎ·
    return {"reply": funny_default_response()}

# === Optional OpenAI fallback ===
@app.post("/openai")
def chat_with_openai(chat: ChatRequest):
    try:
        headers = {
            "Authorization": f"Bearer {settings.openai_api_key}",
            "Content-Type": "application/json",
        }
        data = {
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": chat.message}],
        }
        resp = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=data)
        resp.raise_for_status()
        result = resp.json()
        return {"reply": result["choices"][0]["message"]["content"]}
    except Exception as e:
        logger.error(f"OpenAI error: {e}")
        return {"reply": "âš  Î£Ï†Î¬Î»Î¼Î± OpenAI. Î ÏÎ¿ÏƒÏ€Î¬Î¸Î·ÏƒÎµ Î¾Î±Î½Î¬."}
>>>>>>> 1727f05ffa9b227bfcfe3ba41d5a28c0bb136cc8

# === Health Endpoints ===
@app.get("/")
def root():
    return {"status": "ok"}

@app.get("/healthz")
def healthz():
    return Response("OK", media_type="text/plain")

def create_app():
    return app
